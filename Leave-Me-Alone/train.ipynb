{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory before change: /teamspace/studios/this_studio\n",
      "Directory changed to: NLP-Tutorial-How-to-be-Shakesapeare/Leave-Me-Alone\n",
      "Current directory after change: /teamspace/studios/this_studio/NLP-Tutorial-How-to-be-Shakesapeare/Leave-Me-Alone\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 获取当前工作目录\n",
    "current_directory = os.getcwd()\n",
    "print(f\"Current directory before change: {current_directory}\")\n",
    "\n",
    "# 要更改的目标目录\n",
    "target_directory = 'NLP-Tutorial-How-to-be-Shakesapeare/Leave-Me-Alone'\n",
    "\n",
    "# 如果当前目录不是目标目录，则更改当前工作目录\n",
    "if not current_directory.endswith(target_directory):\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to: {target_directory}\")\n",
    "else:\n",
    "    print(\"Already in the target directory.\")\n",
    "\n",
    "# 获取更改后的当前工作目录地址\n",
    "new_directory = os.getcwd()\n",
    "print(f\"Current directory after change: {new_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at pretrain_results/checkpoint-8682 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import random\n",
    "\n",
    "# 加载IMDb数据集\n",
    "imdb_dataset = load_dataset('imdb')\n",
    "\n",
    "# 随机选取5000条训练样本\n",
    "train_dataset = imdb_dataset['train'].shuffle(seed=42).select(range(5000))\n",
    "\n",
    "# 加载分词器和预训练的模型\n",
    "model_path = 'pretrain_results/checkpoint-8682'\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "\n",
    "# 分词和编码\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# 处理测试集\n",
    "test_dataset = imdb_dataset['test'].map(tokenize_function, batched=True)\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# 定义训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./train_results',\n",
    "    num_train_epochs=5,               # 训练轮次\n",
    "    per_device_train_batch_size=16,   # 每个设备的训练批量大小\n",
    "    per_device_eval_batch_size=16,    # 每个设备的评估批量大小\n",
    "    warmup_steps=500,                 # 预热步数\n",
    "    weight_decay=0.01,                # 权重衰减\n",
    "    logging_dir='./train_logs',             # 日志目录\n",
    "    evaluation_strategy=\"epoch\",      # 在每个 epoch 结束时进行评估\n",
    "    save_strategy=\"epoch\",            # 在每个 epoch 结束时保存模型\n",
    "    load_best_model_at_end=True,      # 在训练结束时加载表现最好的模型\n",
    "    metric_for_best_model=\"accuracy\", # 选择用于模型保存的指标\n",
    ")\n",
    "\n",
    "# 定义计算指标的函数\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# 初始化Trainertrain\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=train_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1565' max='1565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1565/1565 23:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.157512</td>\n",
       "      <td>0.943200</td>\n",
       "      <td>0.943166</td>\n",
       "      <td>0.944150</td>\n",
       "      <td>0.943200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.342200</td>\n",
       "      <td>0.127132</td>\n",
       "      <td>0.949400</td>\n",
       "      <td>0.949311</td>\n",
       "      <td>0.952374</td>\n",
       "      <td>0.949400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.342200</td>\n",
       "      <td>0.048932</td>\n",
       "      <td>0.987200</td>\n",
       "      <td>0.987200</td>\n",
       "      <td>0.987291</td>\n",
       "      <td>0.987200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.011087</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>0.998200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.008431</td>\n",
       "      <td>0.998600</td>\n",
       "      <td>0.998600</td>\n",
       "      <td>0.998600</td>\n",
       "      <td>0.998600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 11:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.008430964313447475, 'eval_accuracy': 0.9986, 'eval_f1': 0.9985999992719949, 'eval_precision': 0.998600078432615, 'eval_recall': 0.9986, 'eval_runtime': 74.9263, 'eval_samples_per_second': 66.732, 'eval_steps_per_second': 4.177, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "trainer.train()\n",
    "\n",
    "# 训练结束后进行评估\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results on the test dataset: {'eval_loss': 0.41011637449264526, 'eval_accuracy': 0.92736, 'eval_f1': 0.9273554432684765, 'eval_precision': 0.9274672539278271, 'eval_recall': 0.92736, 'eval_runtime': 369.4631, 'eval_samples_per_second': 67.666, 'eval_steps_per_second': 4.23, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# 在 test_dataset 上进行评估\n",
    "eval_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "\n",
    "# 打印评估结果\n",
    "print(f\"Evaluation results on the test dataset: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# 定义训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./train_results_baseline',\n",
    "    num_train_epochs=5,               # 训练轮次\n",
    "    per_device_train_batch_size=16,   # 每个设备的训练批量大小\n",
    "    per_device_eval_batch_size=16,    # 每个设备的评估批量大小\n",
    "    warmup_steps=500,                 # 预热步数\n",
    "    weight_decay=0.01,                # 权重衰减\n",
    "    logging_dir='./train_logs_baseline',             # 日志目录\n",
    "    evaluation_strategy=\"epoch\",      # 在每个 epoch 结束时进行评估\n",
    "    save_strategy=\"epoch\",            # 在每个 epoch 结束时保存模型\n",
    "    load_best_model_at_end=True,      # 在训练结束时加载表现最好的模型\n",
    "    metric_for_best_model=\"accuracy\", # 选择用于模型保存的指标\n",
    ")\n",
    "\n",
    "# 定义计算指标的函数\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# 初始化Trainertrain\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=train_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1565' max='1565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1565/1565 23:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.217484</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>0.913362</td>\n",
       "      <td>0.918428</td>\n",
       "      <td>0.913600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>0.091083</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.974997</td>\n",
       "      <td>0.975153</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>0.029569</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>0.992420</td>\n",
       "      <td>0.992400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>0.018142</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>0.995806</td>\n",
       "      <td>0.995800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>0.998400</td>\n",
       "      <td>0.998400</td>\n",
       "      <td>0.998400</td>\n",
       "      <td>0.998400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 07:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.01005455944687128, 'eval_accuracy': 0.9984, 'eval_f1': 0.9984000012800051, 'eval_precision': 0.9984003220488245, 'eval_recall': 0.9984, 'eval_runtime': 75.013, 'eval_samples_per_second': 66.655, 'eval_steps_per_second': 4.173, 'epoch': 5.0}\n",
      "Test results on the test dataset: {'eval_loss': 0.01005455944687128, 'eval_accuracy': 0.9984, 'eval_f1': 0.9984000012800051, 'eval_precision': 0.9984003220488245, 'eval_recall': 0.9984, 'eval_runtime': 75.013, 'eval_samples_per_second': 66.655, 'eval_steps_per_second': 4.173, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "trainer.train()\n",
    "\n",
    "# 训练结束后进行评估\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 06:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results on the test dataset with the loaded baseline model: {'eval_loss': 0.425955206155777, 'eval_model_preparation_time': 0.0022, 'eval_accuracy': 0.92232, 'eval_f1': 0.9223193909840254, 'eval_precision': 0.9223332443705434, 'eval_recall': 0.92232, 'eval_runtime': 366.3155, 'eval_samples_per_second': 68.247, 'eval_steps_per_second': 4.267}\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# 加载预训练的 BERT 模型\n",
    "model_path = 'train_results_baseline/checkpoint-1565'\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "\n",
    "# 初始化Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,  # 使用之前定义的训练参数\n",
    "    eval_dataset=test_dataset,  # 使用测试集进行评估\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# 在 test_dataset 上进行评估\n",
    "eval_results_baseline = trainer.evaluate()\n",
    "\n",
    "# 打印评估结果\n",
    "print(f\"Evaluation results on the test dataset with the loaded baseline model: {eval_results_baseline}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总的来看，预训练后的模型效果是更优的。\n",
    "\n",
    "在训练中的第二轮就展现更快的收敛。\n",
    "\n",
    "在最后的test中，预训练模型也是在loss/acc/f1/recall/prec指标上优于baseline模型（你就说高一点是不是高吧）。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
